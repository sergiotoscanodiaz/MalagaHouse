{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Obtención de datos"
      ],
      "metadata": {
        "id": "LdEWZ7utjK7C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MalagaHouse Scrapping"
      ],
      "metadata": {
        "id": "m7hvGhdStsgJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Trabajo Fin de Máster FP en IA y Big Data realizado por Miguel Gámez Ruiz y Sergio Toscano Díaz*"
      ],
      "metadata": {
        "id": "_dR2wiHFtlGC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Descripción"
      ],
      "metadata": {
        "id": "GgvBMnymUNyw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hemos decidido extraer los datos de viviendas que necesitamos de una página llamada [pisos.com](https://www.pisos.com/venta/pisos-malaga_capital_zona_urbana/).\n",
        "\n",
        "Extraeremos los datos de las distintas zonas de Málaga Capital, para luego proceder al entrenamiento del modelo predictivo del precio de las viviendas."
      ],
      "metadata": {
        "id": "0JcOR25IUO2T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Código"
      ],
      "metadata": {
        "id": "3IsQCgehU1so"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Librerías:"
      ],
      "metadata": {
        "id": "3ZVlAT4VXDVV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hT6peUeScsJE"
      },
      "outputs": [],
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "from csv import writer\n",
        "import re"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Obtención de enlaces a scrapear:"
      ],
      "metadata": {
        "id": "b1_uhgysXCNi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "links = set()\n",
        "\n",
        "# Extraigo enlaces de 74 paginaciones de la página web\n",
        "for p in range(1,74):\n",
        "    if p == 1:\n",
        "        urls = \"https://www.pisos.com/venta/pisos-malaga_capital_zona_urbana/\"\n",
        "    else:\n",
        "        urls = \"https://www.pisos.com/venta/pisos-malaga_capital_zona_urbana/\" + str(p) + '/'\n",
        "\n",
        "    page = requests.get(urls)\n",
        "\n",
        "    soup = BeautifulSoup(page.content, 'html.parser')\n",
        "    lonks = []\n",
        "\n",
        "    for seccion in soup.findAll(\"a\", {\"class\": \"ad-preview__title\"}):\n",
        "        lonk = seccion.get(\"href\")\n",
        "        if \"/comprar/\" in lonk:\n",
        "            link1 = \"https://www.pisos.com\" + lonk\n",
        "            lonks.append(link1)\n",
        "\n",
        "    links.update(lonks)\n",
        "\n",
        "links = list(links)"
      ],
      "metadata": {
        "id": "XSA_stlISd3l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Obtención de datos:"
      ],
      "metadata": {
        "id": "1aOeXnrYaEz5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('housing.csv', 'w', encoding='utf8', newline='') as f:\n",
        "  thewriter = writer(f)\n",
        "  header = ['Tipo', 'Zona', 'Precio', 'Superficie', 'Habitaciones', 'Baños', 'Garaje',\n",
        "          'Trastero', 'Ascensor', 'Terraza', 'Amueblado', 'Chimenea', 'Piscina',\n",
        "          'Jardín', 'Descripción']\n",
        "  thewriter.writerow(header)\n",
        "  \n",
        "  for urls in links:\n",
        "    page = requests.get(urls)\n",
        "    soup = BeautifulSoup(page.content, 'html.parser')\n",
        "\n",
        "    # Extracción de los datos que vamos a utilizar y les creo variables por defecto\n",
        "    datosbasicos = soup.findAll(\"li\", {\"class\": \"charblock-element more-padding\"})\n",
        "    equipamientos = soup.findAll(\"li\", {\"class\": \"charblock-element element-with-bullet\"})\n",
        "\n",
        "    sup = \"\"\n",
        "    hab = \"\"\n",
        "    ban = \"\"\n",
        "    garaje = 0\n",
        "    trastero = 0\n",
        "    ascensor = 0\n",
        "    terraza = 0\n",
        "    amueblado = 0\n",
        "    chimenea = 0\n",
        "    piscina = 0\n",
        "    jardin = 0\n",
        "    ciudad_casa = \"\"\n",
        "    tipo_casa = \"\"\n",
        "    precio = 0\n",
        "\n",
        "    # Obtención del precio\n",
        "    precio_raw = soup.find('span', {\"class\": \"h1 jsPrecioH1\"})\n",
        "    precio = precio_raw.text.strip() if precio_raw is not None else \"0\"\n",
        "    precio = re.sub('[.€]', '', precio).strip()\n",
        "\n",
        "    # Array de los datos\n",
        "    todosdatosbasicos = []\n",
        "    todosequipamientos = []\n",
        "\n",
        "    # Obtención de Superficie, habitaciones y baños\n",
        "    for datobasico in datosbasicos:\n",
        "      datobasico = datobasico.text\n",
        "      todosdatosbasicos.append(datobasico)\n",
        "\n",
        "    for i in todosdatosbasicos:\n",
        "      if \"Superficie construida\" in i:\n",
        "        sup = i\n",
        "      if \"Habitaciones\" in i:\n",
        "        hab = i\n",
        "      if \"Baños\" in i and \":\"in i and not \"Interior\" in i:\n",
        "        ban = i\n",
        "\n",
        "    numeros = re.compile(\"(\\d+)\")\n",
        "    if sup != '':\n",
        "      superficie = [int(superficie) for superficie in str.split(sup) if superficie.isdigit()]\n",
        "      if len(superficie) > 0:\n",
        "        superficie = superficie[0]\n",
        "      else:\n",
        "        superficie = 0\n",
        "    if hab != '':\n",
        "      habitaciones = [int(habitaciones) for habitaciones in str.split(hab) if habitaciones.isdigit()]\n",
        "      habitaciones = habitaciones[0]\n",
        "    if ban != '':\n",
        "        banyos = int(re.search('\\d+', ban).group())\n",
        "\n",
        "    # Obtención del equipamiento\n",
        "    for equipamiento in equipamientos:\n",
        "      equipamiento = equipamiento.text.strip()\n",
        "      todosequipamientos.append(equipamiento)\n",
        "\n",
        "    for i in todosequipamientos:\n",
        "      if \"Garaje\" in i:\n",
        "        garaje = 1\n",
        "      elif \"Trastero\" in i:\n",
        "        trastero = 1\n",
        "      elif \"Ascensor\" in i:\n",
        "        ascensor = 1\n",
        "      elif \"Terraza\" in i:\n",
        "        terraza = 1\n",
        "      elif \"Amueblado\" in i:\n",
        "        amueblado = 1\n",
        "      elif \"Chimenea\" in i:\n",
        "        chimenea = 1\n",
        "      elif \"Piscina\" in i:\n",
        "        piscina = 1\n",
        "      elif \"Jardín\" in i:\n",
        "        jardin = 1\n",
        "\n",
        "    descripcion = soup.find('div', {\"class\": \"description-container description-body\"}).text.strip()\n",
        "\n",
        "    # Obtencion del tipo de vivienda y la localización\n",
        "    a_tipocasa = ['Casa', 'Piso', 'Chalet', 'Ático', 'Dúplex', 'Estudio', 'Finca rústica', 'Loft']\n",
        "\n",
        "    a_zonas = ['Bailén-Miraflores', 'Campanillas', 'Carretera de Cádiz', 'Centro', 'Churriana', \n",
        "                  'Ciudad Jardín', 'Cruz de Humilladero', 'Este', 'La Rosaleda-La Roca', 'Puerto de la Torre', \n",
        "                  'Teatinos-Universidad']\n",
        "\n",
        "    tipo_vivienda = soup.find('h1', {\"class\": \"title\"}).text.strip()\n",
        "    localizacion = soup.find('h2', {\"class\": \"position\"}).text.strip()\n",
        "\n",
        "    for tipo in a_tipocasa:\n",
        "      if tipo in tipo_vivienda:\n",
        "        tipo_casa = tipo\n",
        "\n",
        "    for zona in a_zonas:\n",
        "      if zona in localizacion:\n",
        "        zona_casa = zona\n",
        "\n",
        "    info = [tipo_casa, zona_casa, precio, superficie, habitaciones, banyos, garaje,\n",
        "            trastero, ascensor, terraza, amueblado, chimenea, piscina, jardin,\n",
        "            descripcion]\n",
        "    thewriter.writerow(info)"
      ],
      "metadata": {
        "id": "2FniHRgDcxtM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}